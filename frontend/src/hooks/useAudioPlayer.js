/**
 * Custom hook for managing audio playback of streaming fragments
 * Used by: StreamingAudioPlayer.jsx
 * Purpose: Handles all audio playback logic, fragment management, and backend communication
 * 
 * Flow:
 * 1. Initializes audio player and state
 * 2. Polls backend for new fragments
 * 3. Manages playback state and fragment transitions
 * 4. Handles errors and cleanup
 * 
 * Dependencies:
 * - Backend API endpoints for fragment fetching
 * - Browser's Audio API
 */

import { useState, useEffect, useRef } from 'react';
import { API_ENDPOINTS, API_BASE_URL, POLLING_INTERVALS } from '../utils/constants';

export function useAudioPlayer(videoId, language) {
  console.log('ðŸŽµ Initializing useAudioPlayer:', { videoId, language });
  console.log('ðŸ“ API Base URL:', API_BASE_URL);
  console.log('ðŸ”— Audio fragments endpoint:', API_ENDPOINTS.AUDIO_FRAGMENTS(videoId, language));

  // Player state initialization
  const [isPlaying, setIsPlaying] = useState(false);
  const [isLoading, setIsLoading] = useState(false);
  const [currentFragment, setCurrentFragment] = useState(0);
  const [fragments, setFragments] = useState([]);
  const [error, setError] = useState(null);
  const [volume, setVolume] = useState(1.0);
  const [currentTime, setCurrentTime] = useState(0);
  const [isWaitingForNext, setIsWaitingForNext] = useState(false);

  // Refs initialization
  const audioRef = useRef(null);
  const isUnmountingRef = useRef(false);
  const nextFragmentCheckRef = useRef(null);
  const currentDurationRef = useRef(null);

  const checkBackendAvailability = async () => {
    console.log('ðŸ” Checking backend availability...');
    console.log('ðŸ”— Status endpoint:', API_ENDPOINTS.SERVER_STATUS);
    
    try {
      const response = await fetch(API_ENDPOINTS.SERVER_STATUS);
      console.log('ðŸ“¡ Backend response status:', response.status);
      
      if (!response.ok) {
        console.error('âŒ Backend error:', {
          status: response.status,
          statusText: response.statusText
        });
        throw new Error(`Backend returned status ${response.status} (${response.statusText})`);
      }
      
      const data = await response.json();
      console.log('âœ… Backend status data:', data);
      return true;
    } catch (error) {
      console.error('âŒ Backend availability error:', {
        name: error.name,
        message: error.message,
        stack: error.stack
      });
      setError('Backend server is not available. Please ensure it is running.');
      return false;
    }
  };

  const setupAudioElement = () => {
    console.log('ðŸŽ§ Setting up audio element');
    console.log('Current audio ref state:', {
      exists: !!audioRef.current,
      src: audioRef.current?.src,
      error: audioRef.current?.error
    });

    if (!audioRef.current) {
      audioRef.current = new Audio();
      audioRef.current.volume = volume;
      console.log('ðŸ”Š Initial volume set to:', volume);

      // Debug loading states
      audioRef.current.addEventListener('loadstart', () => {
        console.log('ðŸ”„ Audio loading started:', {
          src: audioRef.current.src,
          readyState: audioRef.current.readyState,
          networkState: audioRef.current.networkState
        });
      });

      audioRef.current.addEventListener('waiting', () => {
        console.log('âŒ› Audio waiting for data:', {
          currentTime: audioRef.current.currentTime,
          buffered: audioRef.current.buffered.length ? 
            [...Array(audioRef.current.buffered.length)].map((_, i) => ({
              start: audioRef.current.buffered.start(i),
              end: audioRef.current.buffered.end(i)
            })) : []
        });
      });

      audioRef.current.addEventListener('stalled', () => {
        console.warn('âš ï¸ Audio download stalled:', {
          src: audioRef.current.src,
          networkState: audioRef.current.networkState
        });
      });

      audioRef.current.addEventListener('suspend', () => {
        console.log('ðŸ” Audio loading suspended:', {
          readyState: audioRef.current.readyState,
          networkState: audioRef.current.networkState
        });
      });

      audioRef.current.addEventListener('canplay', () => {
        console.log('âœ… Audio can start playing:', {
          duration: audioRef.current.duration,
          readyState: audioRef.current.readyState
        });
      });

      audioRef.current.addEventListener('timeupdate', () => {
        const currentTime = audioRef.current.currentTime;
        const duration = audioRef.current.duration;
        setCurrentTime(currentTime);
        currentDurationRef.current = duration;
        
        console.log(`â±ï¸ Playback progress:`, {
          currentTime: currentTime.toFixed(2),
          duration: duration.toFixed(2),
          percentage: ((currentTime / duration) * 100).toFixed(1) + '%',
          readyState: audioRef.current.readyState
        });
      });

      audioRef.current.addEventListener('ended', async () => {
        console.log(`âœ… Fragment ${currentFragment} finished:`, {
          duration: audioRef.current.duration,
          currentTime: audioRef.current.currentTime
        });
        
        const nextFragment = currentFragment + 1;
        console.log('ðŸ“Š Next fragment check:', {
          current: currentFragment,
          next: nextFragment,
          totalFragments: fragments.length,
          hasMore: nextFragment < fragments.length
        });
        
        if (nextFragment < fragments.length) {
          console.log('ðŸ“¥ Moving to next fragment:', nextFragment);
          setCurrentFragment(nextFragment);
          setIsPlaying(true);
        } else {
          console.log('âŒ› Waiting for next fragment...', {
            currentFragment,
            fragmentsAvailable: fragments.length
          });
          setIsWaitingForNext(true);
          setIsLoading(true);
          startFragmentPolling();
        }
      });

      audioRef.current.addEventListener('error', (e) => {
        const error = audioRef.current.error;
        console.error('âŒ Audio error:', {
          code: error.code,
          message: error.message,
          currentSrc: audioRef.current.src,
          readyState: audioRef.current.readyState,
          networkState: audioRef.current.networkState,
          event: e
        });
        
        // Map error codes to meaningful messages
        const errorMessages = {
          1: 'Audio loading aborted',
          2: 'Network error while loading audio',
          3: 'Audio decoding failed',
          4: 'Audio format not supported'
        };
        
        setError(`Failed to play audio: ${errorMessages[error.code] || error.message}`);
        setIsLoading(false);
      });

      console.log('âœ… Audio element setup complete with all event listeners');
    }
  };

  const startFragmentPolling = () => {
    console.log('ðŸ”„ Starting fragment polling:', {
      interval: POLLING_INTERVALS.FRAGMENT_CHECK,
      existingInterval: !!nextFragmentCheckRef.current
    });

    if (nextFragmentCheckRef.current) {
      console.log('ðŸ§¹ Clearing existing poll interval:', nextFragmentCheckRef.current);
      clearInterval(nextFragmentCheckRef.current);
    }
    
    nextFragmentCheckRef.current = setInterval(async () => {
      console.log('ðŸ” Polling for new fragments:', {
        currentFragment,
        totalFragments: fragments.length
      });
      
      const hasNewFragment = await checkForNewFragments();
      console.log('ðŸ“Š Poll result:', {
        hasNewFragment,
        currentFragment,
        fragmentsCount: fragments.length
      });

      if (hasNewFragment) {
        console.log('âœ¨ New fragment found, updating state');
        setIsWaitingForNext(false);
        setIsLoading(false);
        setCurrentFragment(currentFragment + 1);
        setIsPlaying(true);
        clearInterval(nextFragmentCheckRef.current);
      }
    }, POLLING_INTERVALS.FRAGMENT_CHECK);
  };

  const checkForNewFragments = async () => {
    try {
      console.log('ðŸ” Fetching fragments list:', {
        url: API_ENDPOINTS.AUDIO_FRAGMENTS(videoId, language),
        currentCount: fragments.length
      });

      const response = await fetch(API_ENDPOINTS.AUDIO_FRAGMENTS(videoId, language));
      if (!response.ok) {
        console.error('âŒ Fragments fetch error:', {
          status: response.status,
          statusText: response.statusText
        });
        throw new Error(`Failed to fetch fragments: ${response.status} ${response.statusText}`);
      }

      const data = await response.json();
      console.log('ðŸ“¦ Fragments response:', data);
      
      if (data.files && Array.isArray(data.files)) {
        console.log('ðŸ“ Processing files:', data.files);
        const newFragments = data.files
          .filter(f => {
            const isMP3 = f.endsWith('.mp3');
            if (!isMP3) console.warn('âš ï¸ Skipping non-MP3 file:', f);
            return isMP3;
          })
          .sort((a, b) => {
            const numA = parseInt(a.match(/fragment-(\d+)\.mp3/)?.[1] || '0');
            const numB = parseInt(b.match(/fragment-(\d+)\.mp3/)?.[1] || '0');
            return numA - numB;
          });

        console.log('ðŸ“Š Fragments analysis:', {
          current: fragments.length,
          new: newFragments.length,
          difference: newFragments.length - fragments.length,
          newFiles: newFragments.slice(fragments.length)
        });

        if (newFragments.length > fragments.length) {
          console.log(`ðŸ“¥ Found ${newFragments.length - fragments.length} new fragments:`, 
            newFragments.slice(fragments.length));
          setFragments(newFragments);
          
          if (isWaitingForNext && currentFragment + 1 < newFragments.length) {
            console.log('ðŸŽµ Conditions met for auto-play:', {
              isWaiting: isWaitingForNext,
              currentFragment,
              newFragmentsAvailable: newFragments.length
            });
            return true;
          }
          return true;
        }
      } else {
        console.warn('âš ï¸ Unexpected fragments response format:', data);
      }
      return false;
    } catch (error) {
      console.error('âŒ Fragment check error:', {
        name: error.name,
        message: error.message,
        stack: error.stack
      });
      return false;
    }
  };

  const loadAudio = async () => {
    console.log('ðŸ“¥ Load audio called:', {
      currentFragment,
      fragmentsAvailable: fragments.length,
      currentFragmentFile: fragments[currentFragment]
    });

    if (!fragments[currentFragment]) {
      console.warn('âš ï¸ No fragment available to load:', {
        currentFragment,
        fragments,
        fragmentsLength: fragments.length
      });
      return;
    }
    
    const fragmentName = fragments[currentFragment];
    const url = `${API_BASE_URL}/api/audio/${videoId}/${language}/${fragmentName}`;
    console.log('ðŸ”— Audio URL construction:', {
      base: API_BASE_URL,
      videoId,
      language,
      fragment: fragmentName,
      fullUrl: url
    });
    
    if (audioRef.current?.src !== url) {
      console.log('ðŸ“¥ Loading new audio file:', {
        currentSrc: audioRef.current?.src,
        newSrc: url,
        readyState: audioRef.current?.readyState
      });

      try {
        setCurrentTime(0);
        currentDurationRef.current = null;
        audioRef.current.src = url;
        
        console.log('ðŸ”„ Starting audio load');
        await audioRef.current.load();
        console.log('âœ… Audio file loaded successfully:', {
          duration: audioRef.current.duration,
          readyState: audioRef.current.readyState
        });
      } catch (error) {
        console.error('âŒ Audio load error:', {
          name: error.name,
          message: error.message,
          stack: error.stack
        });
        throw error;
      }
    } else {
      console.log('â„¹ï¸ Audio file already loaded:', {
        src: audioRef.current.src,
        readyState: audioRef.current.readyState
      });
    }
  };

  const togglePlay = async () => {
    console.log('ðŸŽµ Toggle play clicked');
    console.log('Current player state:', { 
      isPlaying, 
      currentFragment, 
      fragmentsCount: fragments.length,
      isWaitingForNext,
      currentTime: audioRef.current?.currentTime,
      duration: currentDurationRef.current,
      audioSrc: audioRef.current?.src,
      readyState: audioRef.current?.readyState
    });

    try {
      if (!await checkBackendAvailability()) {
        console.error('âŒ Backend not available for playback');
        throw new Error('Backend is not available');
      }

      if (isPlaying || isWaitingForNext) {
        await pausePlayback();
      } else {
        await startPlayback();
      }
    } catch (error) {
      console.error('âŒ Playback toggle error:', {
        name: error.name,
        message: error.message,
        stack: error.stack,
        playerState: {
          isPlaying,
          isLoading,
          currentFragment,
          fragmentsCount: fragments.length
        }
      });
      setError('Failed to toggle playback: ' + error.message);
      setIsPlaying(false);
      setIsLoading(false);
    }
  };

  const pausePlayback = async () => {
    console.log('â¸ï¸ Pausing playback:', {
      currentTime: audioRef.current?.currentTime,
      duration: audioRef.current?.duration,
      readyState: audioRef.current?.readyState
    });

    try {
      await audioRef.current?.pause();
      setIsPlaying(false);
      setIsWaitingForNext(false);
      setIsLoading(false);
      
      if (nextFragmentCheckRef.current) {
        console.log('ðŸ§¹ Clearing fragment check interval');
        clearInterval(nextFragmentCheckRef.current);
      }
      
      console.log('âœ… Playback paused successfully');
    } catch (error) {
      console.error('âŒ Error pausing playback:', {
        name: error.name,
        message: error.message,
        stack: error.stack
      });
      throw error;
    }
  };

  const startPlayback = async () => {
    console.log('â–¶ï¸ Starting playback:', {
      currentFragment,
      fragmentsCount: fragments.length,
      audioSrc: audioRef.current?.src
    });

    setupAudioElement();
    
    const hasValidTime = audioRef.current?.currentTime !== undefined && 
                       currentDurationRef.current && 
                       !audioRef.current.error;
                       
    const wasAtEnd = hasValidTime && (currentTime >= (currentDurationRef.current - 0.1));
    const hasNewFragments = currentFragment + 1 < fragments.length;

    console.log('Playback state analysis:', {
      hasValidTime,
      wasAtEnd,
      hasNewFragments,
      currentTime,
      duration: currentDurationRef.current,
      readyState: audioRef.current?.readyState,
      networkState: audioRef.current?.networkState
    });

    if (wasAtEnd && !hasNewFragments) {
      console.log('âŒ› At end of fragment, waiting for new ones:', {
        currentFragment,
        fragmentsAvailable: fragments.length
      });
      setIsWaitingForNext(true);
      setIsLoading(true);
      startFragmentPolling();
      return;
    } else if (wasAtEnd && hasNewFragments) {
      console.log('ðŸ“¥ Moving to next available fragment:', {
        current: currentFragment,
        next: currentFragment + 1,
        totalFragments: fragments.length
      });
      setCurrentFragment(currentFragment + 1);
      setIsWaitingForNext(false);
      setIsLoading(false);
      setIsPlaying(true);
      return;
    }

    try {
      if (!audioRef.current.src || audioRef.current.error) {
        console.log('ðŸ”„ Loading audio file:', {
          currentSrc: audioRef.current.src,
          hasError: !!audioRef.current.error
        });
        await loadAudio();
      }
      
      console.log('â–¶ï¸ Starting audio playback');
      await audioRef.current.play();
      console.log('âœ… Playback started successfully:', {
        currentTime: audioRef.current.currentTime,
        duration: audioRef.current.duration,
        readyState: audioRef.current.readyState
      });
      setIsPlaying(true);
    } catch (error) {
      console.error('âŒ Playback start error:', {
        name: error.name,
        message: error.message,
        stack: error.stack,
        audioState: {
          src: audioRef.current?.src,
          readyState: audioRef.current?.readyState,
          networkState: audioRef.current?.networkState
        }
      });
      throw error;
    }
  };

  // Effect: Initial fragment loading and polling
  useEffect(() => {
    console.log('ðŸ”„ Setting up fragment polling:', {
      videoId,
      language,
      isUnmounting: isUnmountingRef.current
    });

    const checkFragments = async () => {
      if (isUnmountingRef.current) {
        console.log('âš ï¸ Skipping fragment check - component unmounting');
        return;
      }
      await checkForNewFragments();
    };

    checkFragments();
    const interval = setInterval(checkFragments, POLLING_INTERVALS.FRAGMENT_CHECK);
    console.log('âœ… Fragment polling interval set:', interval);

    return () => {
      console.log('ðŸ§¹ Cleaning up audio player:', {
        videoId,
        language,
        hasAudioRef: !!audioRef.current,
        hasInterval: !!interval
      });
      isUnmountingRef.current = true;
      clearInterval(interval);
      if (nextFragmentCheckRef.current) {
        clearInterval(nextFragmentCheckRef.current);
      }
      if (audioRef.current) {
        audioRef.current.pause();
        audioRef.current.src = '';
        audioRef.current = null;
      }
    };
  }, [videoId, language]);

  // Effect: Handle fragment changes
  useEffect(() => {
    console.log('ðŸ”„ Fragment changed:', {
      currentFragment,
      totalFragments: fragments.length,
      isPlaying,
      isWaitingForNext
    });

    const loadAndPlay = async () => {
      try {
        if (isPlaying || (!isPlaying && !isWaitingForNext)) {
          const currentUrl = audioRef.current?.src;
          const newUrl = `${API_BASE_URL}/api/audio/${videoId}/${language}/${fragments[currentFragment]}`;
          
          console.log('URL comparison:', {
            current: currentUrl,
            new: newUrl,
            needsUpdate: currentUrl !== newUrl
          });

          if (currentUrl !== newUrl) {
            await loadAudio();
            if (isPlaying) {
              console.log('â–¶ï¸ Auto-playing next fragment');
              try {
                await audioRef.current?.play();
                console.log('âœ… Auto-play successful');
              } catch (error) {
                console.error('âŒ Auto-play failed:', {
                  name: error.name,
                  message: error.message,
                  stack: error.stack
                });
                setIsPlaying(false);
              }
            }
          }
        }
      } catch (error) {
        console.error('âŒ Fragment change error:', {
          name: error.name,
          message: error.message,
          stack: error.stack,
          fragmentState: {
            current: currentFragment,
            total: fragments.length,
            isPlaying,
            isWaitingForNext
          }
        });
        setError('Failed to play audio');
        setIsPlaying(false);
      }
    };

    loadAndPlay();
  }, [currentFragment]);

  // Effect: Handle play state changes
  useEffect(() => {
    console.log('ðŸ”„ Play state changed:', {
      isPlaying,
      currentFragment,
      hasAudioRef: !!audioRef.current,
      audioError: audioRef.current?.error
    });

    const handlePlayStateChange = async () => {
      try {
        if (isPlaying && audioRef.current && !audioRef.current.error) {
          if (audioRef.current.paused) {
            console.log('â–¶ï¸ Resuming playback:', {
              currentTime: audioRef.current.currentTime,
              duration: audioRef.current.duration,
              readyState: audioRef.current.readyState
            });
            
            try {
              await audioRef.current.play();
              console.log('âœ… Resume successful');
            } catch (error) {
              console.error('âŒ Resume failed:', {
                name: error.name,
                message: error.message,
                stack: error.stack
              });
              setIsPlaying(false);
            }
          }
        }
      } catch (error) {
        console.error('âŒ Play state change error:', {
          name: error.name,
          message: error.message,
          stack: error.stack,
          audioState: {
            paused: audioRef.current?.paused,
            readyState: audioRef.current?.readyState,
            networkState: audioRef.current?.networkState
          }
        });
        setError('Failed to play audio');
        setIsPlaying(false);
      }
    };

    handlePlayStateChange();
  }, [isPlaying]);

  // Effect: Handle volume changes
  useEffect(() => {
    console.log('ðŸ”Š Volume changed:', {
      newVolume: volume,
      hasAudioRef: !!audioRef.current,
      currentVolume: audioRef.current?.volume
    });
    
    if (audioRef.current) {
      audioRef.current.volume = volume;
    }
  }, [volume]);

  return {
    isPlaying,
    isLoading,
    currentFragment,
    fragments,
    error,
    volume,
    currentTime,
    isWaitingForNext,
    setVolume,
    setError,
    togglePlay
  };
} 